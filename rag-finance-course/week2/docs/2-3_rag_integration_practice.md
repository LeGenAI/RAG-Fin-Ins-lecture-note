# 2-3. .md, .json í˜•íƒœ ë³€í™˜ ì‹¤ìŠµ (RAG ì‹œìŠ¤í…œ ì—°ê³„)

## í•™ìŠµ ëª©í‘œ
- ë³€í™˜ëœ ë°ì´í„°ë¥¼ ë²¡í„° DBì— ì €ì¥í•˜ëŠ” ë°©ë²• í•™ìŠµ
- ChromaDBì™€ Pineconeì„ í™œìš©í•œ ì‹¤ìŠµ
- LangChainì„ í†µí•œ RAG ì‹œìŠ¤í…œ êµ¬ì¶•
- ì‹¤ì œ ê¸ˆìœµ ì±—ë´‡ êµ¬í˜„ ì‚¬ë¡€ ë¶„ì„

---

## 1. RAG ì‹œìŠ¤í…œ ê°œìš”

### 1.1 RAG(Retrieval-Augmented Generation)ë€?

**ì •ì˜**
- ê²€ìƒ‰(Retrieval)ê³¼ ìƒì„±(Generation)ì„ ê²°í•©í•œ AI ì‹œìŠ¤í…œ
- ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ ë” ì •í™•í•˜ê³  ìµœì‹ ì˜ ë‹µë³€ ìƒì„±
- ê¸ˆìœµ ë°ì´í„°ì˜ ì‹¤ì‹œê°„ì„±ê³¼ ì •í™•ì„± ìš”êµ¬ì‚¬í•­ ì¶©ì¡±

**RAG ì‹œìŠ¤í…œì˜ êµ¬ì„± ìš”ì†Œ**
```
[ì‚¬ìš©ì ì§ˆë¬¸] â†’ [ì„ë² ë”© ë³€í™˜] â†’ [ë²¡í„° DB ê²€ìƒ‰] â†’ [ê´€ë ¨ ë¬¸ì„œ ì¶”ì¶œ]
                                                          â†“
[ì‚¬ìš©ì ë‹µë³€] â† [LLM ë‹µë³€ ìƒì„±] â† [í”„ë¡¬í”„íŠ¸ + ê²€ìƒ‰ ê²°ê³¼ ê²°í•©]
```

### 1.2 ê¸ˆìœµ ë¶„ì•¼ RAG í™œìš© ì‚¬ë¡€

#### êµ­ë‚´ ì‚¬ë¡€

**KBêµ­ë¯¼ì€í–‰ KB-STA**
- ìì²´ ê°œë°œ AI ëª¨ë¸
- ë§ˆì´ë°ì´í„° + RAG ê¸°ë°˜ ë§ì¶¤í˜• ìì‚°ê´€ë¦¬
- ì‹¤ì‹œê°„ ì‹œì¥ ë°ì´í„° ë°˜ì˜

**ì‹ í•œì€í–‰ AI ë±…ì»¤**
- 150ì—¬ ëŒ€ ë””ì§€í„¸ ë°ìŠ¤í¬ ë°°ì¹˜
- ê³ ê° ê±°ë˜ ì´ë ¥ ê¸°ë°˜ ìƒí’ˆ ì¶”ì²œ
- RAGë¥¼ í†µí•œ ìƒí’ˆ ì„¤ëª…ì„œ ì‹¤ì‹œê°„ ê²€ìƒ‰

#### í•´ì™¸ ì‚¬ë¡€

**Morgan Stanley AI @ Morgan Stanley Assistant**
- 98% ì¬ë¬´ ìƒë‹´ì‚¬ í™œìš©
- 100,000ê°œ ì´ìƒ ì—°êµ¬ ë³´ê³ ì„œ DB
- GPT-4 ê¸°ë°˜ RAG ì‹œìŠ¤í…œ

**JP Morgan LLM Suite**
- 60,000ëª… ì´ìƒ ì§ì› ì‚¬ìš©
- 400ê°œ ì´ìƒ í™œìš© ì‚¬ë¡€
- ë‚´ë¶€ ë¬¸ì„œ + ì™¸ë¶€ ë°ì´í„° í†µí•© RAG

---

## 2. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•

### 2.1 ChromaDB ì‹¤ìŠµ

#### ì„¤ì¹˜ ë° ì´ˆê¸° ì„¤ì •

```bash
# ChromaDB ì„¤ì¹˜
pip install chromadb
pip install sentence-transformers
pip install openai
```

#### ê¸ˆìœµ ë°ì´í„° ë²¡í„°í™” ë° ì €ì¥

```python
import chromadb
from chromadb.config import Settings
import json
from sentence_transformers import SentenceTransformer
from datetime import datetime
import hashlib

class FinancialVectorDB:
    def __init__(self, db_path="./financial_vector_db"):
        """ê¸ˆìœµ ë°ì´í„° ì „ìš© ë²¡í„° DB ì´ˆê¸°í™”"""
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        self.client = chromadb.PersistentClient(
            path=db_path,
            settings=Settings(
                anonymized_telemetry=False,
                allow_reset=True
            )
        )
        
        # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (í•œêµ­ì–´ ì§€ì›)
        self.embedding_model = SentenceTransformer('jhgan/ko-sroberta-multitask')
        
        # ì»¬ë ‰ì…˜ ìƒì„±
        self.collections = {
            'transactions': self._create_or_get_collection('transactions'),
            'products': self._create_or_get_collection('products'),
            'policies': self._create_or_get_collection('policies'),
            'customer_profiles': self._create_or_get_collection('customer_profiles')
        }
    
    def _create_or_get_collection(self, name):
        """ì»¬ë ‰ì…˜ ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°"""
        try:
            return self.client.get_collection(name)
        except:
            return self.client.create_collection(
                name=name,
                metadata={"description": f"Collection for {name}"}
            )
    
    def add_transactions(self, transactions_json, user_id):
        """ê±°ë˜ ë°ì´í„° ë²¡í„°í™” ë° ì €ì¥"""
        transactions = json.loads(transactions_json)
        
        documents = []
        metadatas = []
        ids = []
        embeddings = []
        
        for i, trans in enumerate(transactions):
            # ìì—°ì–´ ë¬¸ì„œ ìƒì„±
            doc = self._create_transaction_document(trans)
            documents.append(doc)
            
            # ë©”íƒ€ë°ì´í„° ìƒì„±
            metadata = {
                'user_id': user_id,
                'date': trans['date'],
                'amount': float(trans['amount']),
                'type': trans['type'],
                'category': trans.get('category', 'unknown'),
                'merchant': trans.get('merchant', 'unknown')
            }
            metadatas.append(metadata)
            
            # ê³ ìœ  ID ìƒì„±
            unique_string = f"{user_id}_{trans['date']}_{trans['amount']}_{i}"
            doc_id = hashlib.md5(unique_string.encode()).hexdigest()
            ids.append(doc_id)
            
            # ì„ë² ë”© ìƒì„±
            embedding = self.embedding_model.encode(doc).tolist()
            embeddings.append(embedding)
        
        # ë²¡í„° DBì— ì €ì¥
        self.collections['transactions'].add(
            documents=documents,
            embeddings=embeddings,
            metadatas=metadatas,
            ids=ids
        )
        
        return f"âœ… {len(documents)}ê±´ì˜ ê±°ë˜ ë°ì´í„°ê°€ ë²¡í„° DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
    
    def _create_transaction_document(self, transaction):
        """ê±°ë˜ ë°ì´í„°ë¥¼ ìì—°ì–´ ë¬¸ì„œë¡œ ë³€í™˜"""
        doc = f"""
        ê±°ë˜ì¼ì‹œ: {transaction['date']} {transaction.get('time', '')}
        ê±°ë˜ìœ í˜•: {transaction['type']}
        ê±°ë˜ê¸ˆì•¡: {transaction['amount']:,}ì›
        ê±°ë˜ì²˜: {transaction.get('merchant', transaction.get('description', ''))}
        ì¹´í…Œê³ ë¦¬: {transaction.get('category', 'ë¯¸ë¶„ë¥˜')}
        ê±°ë˜í›„ì”ì•¡: {transaction.get('balance', 0):,}ì›
        """
        
        # AI ì¸ì‚¬ì´íŠ¸ ì¶”ê°€
        if transaction.get('ai_insights'):
            insights = transaction['ai_insights']
            doc += f"""
        ì†Œë¹„íŒ¨í„´: {insights.get('spending_pattern', '')}
        ì˜ˆì‚°ì˜í–¥: {insights.get('budget_impact', '')}
        """
        
        return doc.strip()
    
    def search_transactions(self, query, user_id=None, n_results=5):
        """ê±°ë˜ ë°ì´í„° ê²€ìƒ‰"""
        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embedding = self.embedding_model.encode(query).tolist()
        
        # ê²€ìƒ‰ ì¡°ê±´ ì„¤ì •
        where_clause = {"user_id": user_id} if user_id else None
        
        # ê²€ìƒ‰ ì‹¤í–‰
        results = self.collections['transactions'].query(
            query_embeddings=[query_embedding],
            n_results=n_results,
            where=where_clause
        )
        
        return self._format_search_results(results)
    
    def _format_search_results(self, results):
        """ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…"""
        formatted_results = []
        
        if results['documents'] and results['documents'][0]:
            for i, doc in enumerate(results['documents'][0]):
                result = {
                    'document': doc,
                    'metadata': results['metadatas'][0][i] if results['metadatas'] else {},
                    'distance': results['distances'][0][i] if results['distances'] else 0
                }
                formatted_results.append(result)
        
        return formatted_results
    
    def add_insurance_policies(self, policies_data, user_id):
        """ë³´í—˜ ì•½ê´€ ë°ì´í„° ì €ì¥"""
        documents = []
        metadatas = []
        ids = []
        embeddings = []
        
        for policy_id, policy in policies_data.items():
            # ì•½ê´€ì„ ìì—°ì–´ë¡œ ë³€í™˜
            doc = f"""
            ë³´í—˜ìƒí’ˆëª…: {policy['name']}
            ë³´í—˜ì‚¬: {policy['company']}
            ë³´ì¥ë‚´ìš©: {policy['coverage']}
            ì›”ë³´í—˜ë£Œ: {policy['premium']:,}ì›
            ë³´ì¥ê¸°ê°„: {policy['term']}
            ê°€ì…ì¼ì: {policy['start_date']}
            íŠ¹ì•½ì‚¬í•­: {', '.join(policy.get('special_terms', []))}
            """
            
            documents.append(doc.strip())
            
            metadata = {
                'user_id': user_id,
                'policy_id': policy_id,
                'company': policy['company'],
                'product_type': policy.get('type', 'unknown'),
                'premium': policy['premium'],
                'start_date': policy['start_date']
            }
            metadatas.append(metadata)
            
            ids.append(f"{user_id}_{policy_id}")
            
            # ì„ë² ë”© ìƒì„±
            embedding = self.embedding_model.encode(doc).tolist()
            embeddings.append(embedding)
        
        # ì €ì¥
        self.collections['policies'].add(
            documents=documents,
            embeddings=embeddings,
            metadatas=metadatas,
            ids=ids
        )
        
        return f"âœ… {len(documents)}ê°œì˜ ë³´í—˜ ìƒí’ˆì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."

# ì‚¬ìš© ì˜ˆì‹œ
vector_db = FinancialVectorDB()

# ê±°ë˜ ë°ì´í„° ì €ì¥
sample_transactions = json.dumps([
    {
        "date": "2024-01-15",
        "time": "14:30:25",
        "type": "withdrawal",
        "amount": 4500,
        "merchant": "ìŠ¤íƒ€ë²…ìŠ¤ ê°•ë‚¨ì ",
        "category": "ì¹´í˜",
        "balance": 2450000
    },
    {
        "date": "2024-01-15",
        "time": "09:15:10",
        "type": "deposit",
        "amount": 2800000,
        "description": "ê¸‰ì—¬",
        "category": "ìˆ˜ì…",
        "balance": 5250000
    }
])

result = vector_db.add_transactions(sample_transactions, "user123")
print(result)

# ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
search_results = vector_db.search_transactions("ìŠ¤íƒ€ë²…ìŠ¤ì—ì„œ ì“´ ëˆ", "user123")
for result in search_results:
    print(f"ë¬¸ì„œ: {result['document'][:100]}...")
    print(f"ìœ ì‚¬ë„: {1 - result['distance']:.2f}\n")
```

### 2.2 Pinecone ì‹¤ìŠµ

#### ì„¤ì¹˜ ë° ì´ˆê¸° ì„¤ì •

```bash
# Pinecone ì„¤ì¹˜
pip install pinecone-client
pip install sentence-transformers
```

#### Pineconeì„ í™œìš©í•œ ëŒ€ê·œëª¨ ê¸ˆìœµ ë°ì´í„° ê´€ë¦¬

```python
import pinecone
from sentence_transformers import SentenceTransformer
import json
import os
from typing import List, Dict
import numpy as np

class PineconeFinancialDB:
    def __init__(self, api_key, environment="us-west1-gcp"):
        """Pinecone ê¸°ë°˜ ê¸ˆìœµ ë²¡í„° DB ì´ˆê¸°í™”"""
        
        # Pinecone ì´ˆê¸°í™”
        pinecone.init(api_key=api_key, environment=environment)
        
        # ì„ë² ë”© ëª¨ë¸ (384ì°¨ì›)
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # ì¸ë±ìŠ¤ ì„¤ì •
        self.index_name = "financial-data-rag"
        self.dimension = 384
        
        # ì¸ë±ìŠ¤ ìƒì„± ë˜ëŠ” ì—°ê²°
        self._setup_index()
    
    def _setup_index(self):
        """ì¸ë±ìŠ¤ ìƒì„± ë˜ëŠ” ì—°ê²°"""
        if self.index_name not in pinecone.list_indexes():
            pinecone.create_index(
                name=self.index_name,
                dimension=self.dimension,
                metric="cosine",
                metadata_config={
                    "indexed": ["user_id", "category", "date"]
                }
            )
            print(f"âœ… ì¸ë±ìŠ¤ '{self.index_name}' ìƒì„± ì™„ë£Œ")
        
        self.index = pinecone.Index(self.index_name)
        
        # ì¸ë±ìŠ¤ í†µê³„ í™•ì¸
        stats = self.index.describe_index_stats()
        print(f"ğŸ“Š ì¸ë±ìŠ¤ í†µê³„: {stats}")
    
    def upsert_financial_documents(self, documents: List[Dict], batch_size=100):
        """ëŒ€ëŸ‰ì˜ ê¸ˆìœµ ë¬¸ì„œ ì—…ì„œíŠ¸"""
        vectors = []
        
        for doc in documents:
            # í…ìŠ¤íŠ¸ ìƒì„±
            text = self._create_document_text(doc)
            
            # ì„ë² ë”© ìƒì„±
            embedding = self.model.encode(text).tolist()
            
            # ë²¡í„° ë°ì´í„° êµ¬ì„±
            vector = {
                'id': doc['id'],
                'values': embedding,
                'metadata': {
                    'user_id': doc.get('user_id'),
                    'type': doc.get('type'),
                    'category': doc.get('category'),
                    'amount': float(doc.get('amount', 0)),
                    'date': doc.get('date'),
                    'text': text[:1000]  # ë©”íƒ€ë°ì´í„° í¬ê¸° ì œí•œ
                }
            }
            vectors.append(vector)
            
            # ë°°ì¹˜ ì²˜ë¦¬
            if len(vectors) >= batch_size:
                self.index.upsert(vectors=vectors)
                print(f"ğŸ“¤ {len(vectors)}ê°œ ë²¡í„° ì—…ì„œíŠ¸ ì™„ë£Œ")
                vectors = []
        
        # ë‚¨ì€ ë²¡í„° ì²˜ë¦¬
        if vectors:
            self.index.upsert(vectors=vectors)
            print(f"ğŸ“¤ {len(vectors)}ê°œ ë²¡í„° ì—…ì„œíŠ¸ ì™„ë£Œ")
        
        return f"âœ… ì´ {len(documents)}ê°œ ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ"
    
    def _create_document_text(self, doc):
        """ë¬¸ì„œë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        if doc.get('type') == 'transaction':
            return f"""
            ê±°ë˜ì¼: {doc.get('date')}
            ê±°ë˜ìœ í˜•: {doc.get('transaction_type')}
            ê¸ˆì•¡: {doc.get('amount'):,}ì›
            ìƒí˜¸ëª…: {doc.get('merchant', '')}
            ì¹´í…Œê³ ë¦¬: {doc.get('category', '')}
            ì„¤ëª…: {doc.get('description', '')}
            """
        elif doc.get('type') == 'insurance':
            return f"""
            ë³´í—˜ìƒí’ˆ: {doc.get('product_name')}
            ë³´í—˜ì‚¬: {doc.get('company')}
            ì›”ë³´í—˜ë£Œ: {doc.get('premium'):,}ì›
            ë³´ì¥ë‚´ìš©: {doc.get('coverage')}
            """
        else:
            return doc.get('text', '')
    
    def hybrid_search(self, query: str, user_id: str = None, 
                      filters: Dict = None, top_k: int = 10):
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ì˜ë¯¸ + ë©”íƒ€ë°ì´í„°)"""
        
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = self.model.encode(query).tolist()
        
        # í•„í„° êµ¬ì„±
        filter_dict = {}
        if user_id:
            filter_dict['user_id'] = user_id
        if filters:
            filter_dict.update(filters)
        
        # ê²€ìƒ‰ ì‹¤í–‰
        results = self.index.query(
            vector=query_embedding,
            filter=filter_dict if filter_dict else None,
            top_k=top_k,
            include_metadata=True
        )
        
        return self._format_results(results)
    
    def _format_results(self, results):
        """ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…"""
        formatted = []
        
        for match in results['matches']:
            formatted.append({
                'id': match['id'],
                'score': match['score'],
                'metadata': match.get('metadata', {}),
                'text': match.get('metadata', {}).get('text', '')
            })
        
        return formatted
    
    def delete_user_data(self, user_id: str):
        """íŠ¹ì • ì‚¬ìš©ì ë°ì´í„° ì‚­ì œ (GDPR ì¤€ìˆ˜)"""
        # ì‚¬ìš©ì ë°ì´í„° ì¡°íšŒ
        results = self.index.query(
            vector=[0] * self.dimension,  # ë”ë¯¸ ë²¡í„°
            filter={'user_id': user_id},
            top_k=10000
        )
        
        # ID ì¶”ì¶œ
        ids_to_delete = [match['id'] for match in results['matches']]
        
        # ì‚­ì œ ì‹¤í–‰
        if ids_to_delete:
            self.index.delete(ids=ids_to_delete)
            return f"âœ… {len(ids_to_delete)}ê°œ ë¬¸ì„œ ì‚­ì œ ì™„ë£Œ"
        else:
            return "âš ï¸ ì‚­ì œí•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤"

# ì‚¬ìš© ì˜ˆì‹œ
pinecone_db = PineconeFinancialDB(
    api_key="your-pinecone-api-key",
    environment="us-west1-gcp"
)

# ëŒ€ëŸ‰ ë°ì´í„° ì¤€ë¹„
documents = [
    {
        'id': 'trans_001',
        'user_id': 'user123',
        'type': 'transaction',
        'date': '2024-01-15',
        'amount': 50000,
        'merchant': 'ì´ë§ˆíŠ¸',
        'category': 'ì‡¼í•‘'
    },
    {
        'id': 'ins_001',
        'user_id': 'user123',
        'type': 'insurance',
        'product_name': 'ì‹¤ì†ì˜ë£Œë³´í—˜',
        'company': 'KBì†í•´ë³´í—˜',
        'premium': 35000,
        'coverage': 'ì…ì›/í†µì› ì˜ë£Œë¹„'
    }
]

# ë°ì´í„° ì—…ì„œíŠ¸
result = pinecone_db.upsert_financial_documents(documents)
print(result)

# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
search_results = pinecone_db.hybrid_search(
    query="ì´ë§ˆíŠ¸ ì‡¼í•‘ ë‚´ì—­",
    user_id="user123",
    filters={'category': 'ì‡¼í•‘'}
)

for result in search_results:
    print(f"ID: {result['id']}")
    print(f"ì ìˆ˜: {result['score']:.3f}")
    print(f"ë©”íƒ€ë°ì´í„°: {result['metadata']}\n")
```

---

## 3. LangChainì„ í™œìš©í•œ RAG ì‹œìŠ¤í…œ êµ¬ì¶•

### 3.1 LangChain ê¸°ë³¸ ì„¤ì •

```bash
# LangChain ë° ê´€ë ¨ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install langchain
pip install langchain-openai
pip install langchain-community
pip install chromadb
pip install tiktoken
```

### 3.2 ê¸ˆìœµ RAG ì±—ë´‡ êµ¬í˜„

```python
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA, ConversationalRetrievalChain
from langchain.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import JSONLoader
import os
from typing import List, Dict

class FinancialRAGChatbot:
    def __init__(self, openai_api_key: str, db_path: str = "./financial_rag_db"):
        """ê¸ˆìœµ RAG ì±—ë´‡ ì´ˆê¸°í™”"""
        
        # OpenAI API ì„¤ì •
        os.environ["OPENAI_API_KEY"] = openai_api_key
        
        # ì„ë² ë”© ëª¨ë¸
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-ada-002"
        )
        
        # LLM ì„¤ì • (GPT-4 ì‚¬ìš©)
        self.llm = ChatOpenAI(
            model="gpt-4",
            temperature=0.1,
            max_tokens=1000
        )
        
        # ë²¡í„° ìŠ¤í† ì–´
        self.vectorstore = Chroma(
            persist_directory=db_path,
            embedding_function=self.embeddings
        )
        
        # ëŒ€í™” ë©”ëª¨ë¦¬
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True,
            output_key="answer"
        )
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self.qa_prompt = self._create_qa_prompt()
        
        # RAG ì²´ì¸ ìƒì„±
        self.qa_chain = self._create_qa_chain()
    
    def _create_qa_prompt(self):
        """ì§ˆì˜ì‘ë‹µ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        template = """ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ AI ê¸ˆìœµ ë¹„ì„œì…ë‹ˆë‹¤. 
        ì‚¬ìš©ìì˜ ê¸ˆìœµ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ë§ì¶¤í˜• ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.
        
        ë‹¤ìŒ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:
        
        ì°¸ê³  ì •ë³´:
        {context}
        
        ëŒ€í™” ê¸°ë¡:
        {chat_history}
        
        ì‚¬ìš©ì ì§ˆë¬¸: {question}
        
        ë‹µë³€ ì‹œ ì§€ì¹¨:
        1. ì •í™•í•œ ìˆ˜ì¹˜ì™€ ë‚ ì§œë¥¼ ì œì‹œí•˜ì„¸ìš”
        2. ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•˜ë‹¤ê³  ì•ˆë‚´í•˜ì„¸ìš”
        3. ê¸ˆìœµ ì „ë¬¸ ìš©ì–´ëŠ” ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”
        4. ê°œì¸í™”ëœ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”
        5. í•„ìš”ì‹œ ì¶”ê°€ í–‰ë™ ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”
        
        ë‹µë³€:"""
        
        return PromptTemplate(
            template=template,
            input_variables=["context", "chat_history", "question"]
        )
    
    def _create_qa_chain(self):
        """QA ì²´ì¸ ìƒì„±"""
        return ConversationalRetrievalChain.from_llm(
            llm=self.llm,
            retriever=self.vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 5}
            ),
            memory=self.memory,
            combine_docs_chain_kwargs={"prompt": self.qa_prompt},
            return_source_documents=True,
            verbose=True
        )
    
    def load_financial_data(self, data_path: str):
        """ê¸ˆìœµ ë°ì´í„° ë¡œë“œ ë° ë²¡í„°í™”"""
        
        # JSON ë°ì´í„° ë¡œë“œ
        loader = JSONLoader(
            file_path=data_path,
            jq_schema=".transactions[]",
            text_content=False
        )
        documents = loader.load()
        
        # í…ìŠ¤íŠ¸ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            separators=["\n\n", "\n", " ", ""]
        )
        
        split_docs = text_splitter.split_documents(documents)
        
        # ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
        self.vectorstore.add_documents(split_docs)
        
        return f"âœ… {len(split_docs)}ê°œ ë¬¸ì„œ ì²­í¬ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤"
    
    def chat(self, question: str, user_id: str = None):
        """ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€"""
        
        # ì‚¬ìš©ìë³„ í•„í„°ë§ (ì˜µì…˜)
        if user_id:
            self.qa_chain.retriever.search_kwargs["filter"] = {"user_id": user_id}
        
        try:
            # ë‹µë³€ ìƒì„±
            result = self.qa_chain({"question": question})
            
            # ì†ŒìŠ¤ ë¬¸ì„œ ì •ë³´ ì¶”ì¶œ
            sources = []
            if result.get("source_documents"):
                for doc in result["source_documents"]:
                    sources.append({
                        "content": doc.page_content[:200],
                        "metadata": doc.metadata
                    })
            
            return {
                "answer": result["answer"],
                "sources": sources,
                "conversation_id": self.memory.chat_memory.messages[-1].id if self.memory.chat_memory.messages else None
            }
            
        except Exception as e:
            return {
                "answer": f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "sources": [],
                "error": True
            }
    
    def get_spending_analysis(self, user_id: str, period: str = "1ê°œì›”"):
        """ì§€ì¶œ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        question = f"""
        ìµœê·¼ {period} ë™ì•ˆì˜ ì§€ì¶œ íŒ¨í„´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.
        ë‹¤ìŒ í•­ëª©ì„ í¬í•¨í•´ì£¼ì„¸ìš”:
        1. ì¹´í…Œê³ ë¦¬ë³„ ì§€ì¶œ ë¹„ì¤‘
        2. ì „ì›” ëŒ€ë¹„ ì¦ê°
        3. ì´ìƒ ì§€ì¶œ íŒ¨í„´
        4. ì ˆì•½ ê°€ëŠ¥ í•­ëª©
        5. ë§ì¶¤í˜• ì ˆì•½ íŒ
        """
        return self.chat(question, user_id)
    
    def get_investment_recommendation(self, user_id: str):
        """íˆ¬ì ì¶”ì²œ ìƒì„±"""
        question = """
        ë‚´ í˜„ì¬ ì¬ë¬´ ìƒí™©ê³¼ ê±°ë˜ íŒ¨í„´ì„ ê³ ë ¤í•˜ì—¬:
        1. ì í•©í•œ íˆ¬ì ìƒí’ˆì„ ì¶”ì²œí•´ì£¼ì„¸ìš”
        2. íˆ¬ì ê°€ëŠ¥ ê¸ˆì•¡ì„ ì œì•ˆí•´ì£¼ì„¸ìš”
        3. ë¦¬ìŠ¤í¬ ìˆ˜ì¤€ì„ í‰ê°€í•´ì£¼ì„¸ìš”
        4. í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±ì„ ì œì•ˆí•´ì£¼ì„¸ìš”
        """
        return self.chat(question, user_id)
    
    def get_insurance_review(self, user_id: str):
        """ë³´í—˜ ë¦¬ë·° ìƒì„±"""
        question = """
        ë‚´ í˜„ì¬ ë³´í—˜ ê°€ì… í˜„í™©ì„ ê²€í† í•˜ê³ :
        1. ë³´ì¥ ê³µë°±ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
        2. ì¤‘ë³µ ë³´ì¥ì´ ìˆëŠ”ì§€ ë¶„ì„í•´ì£¼ì„¸ìš”
        3. ë³´í—˜ë£Œ ì ì •ì„±ì„ í‰ê°€í•´ì£¼ì„¸ìš”
        4. ì¶”ê°€ë¡œ í•„ìš”í•œ ë³´ì¥ì„ ì œì•ˆí•´ì£¼ì„¸ìš”
        """
        return self.chat(question, user_id)
    
    def clear_memory(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        self.memory.clear()
        return "âœ… ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤"

# ì‚¬ìš© ì˜ˆì‹œ
chatbot = FinancialRAGChatbot(
    openai_api_key="your-openai-api-key"
)

# ë°ì´í„° ë¡œë“œ
chatbot.load_financial_data("financial_data.json")

# ëŒ€í™” ì‹œì‘
questions = [
    "ì´ë²ˆ ë‹¬ ì¹´í˜ì—ì„œ ì–¼ë§ˆë‚˜ ì¼ë‚˜ìš”?",
    "ì§€ë‚œ 3ê°œì›” í‰ê·  ì§€ì¶œì•¡ì€ ì–¼ë§ˆì¸ê°€ìš”?",
    "ë‚´ ì†Œë¹„ íŒ¨í„´ì—ì„œ ì ˆì•½í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„ì´ ìˆë‚˜ìš”?",
    "í˜„ì¬ ë‚´ ìƒí™©ì— ë§ëŠ” ì ê¸ˆ ìƒí’ˆì„ ì¶”ì²œí•´ì£¼ì„¸ìš”"
]

for question in questions:
    print(f"\nğŸ‘¤ ì§ˆë¬¸: {question}")
    response = chatbot.chat(question, user_id="user123")
    print(f"ğŸ¤– ë‹µë³€: {response['answer']}")
    
    if response['sources']:
        print("\nğŸ“š ì°¸ê³  ìë£Œ:")
        for source in response['sources']:
            print(f"  - {source['content'][:100]}...")
```

---

## 4. ì‹¤ì œ ê¸ˆìœµê¸°ê´€ êµ¬í˜„ ì‚¬ë¡€

### 4.1 Morgan Stanleyì˜ AI @ Morgan Stanley Assistant

```python
# Morgan Stanley ìŠ¤íƒ€ì¼ RAG êµ¬í˜„ ì˜ˆì‹œ
class MorganStanleyStyleRAG:
    """Morgan Stanleyì˜ RAG ì‹œìŠ¤í…œì„ ëª¨ë°©í•œ êµ¬í˜„"""
    
    def __init__(self):
        self.research_db = self._init_research_db()
        self.client_db = self._init_client_db()
        self.market_db = self._init_market_db()
    
    def _init_research_db(self):
        """100,000ê°œ ì´ìƒì˜ ì—°êµ¬ ë³´ê³ ì„œ DB"""
        return {
            "total_documents": 100000,
            "categories": [
                "Equity Research",
                "Fixed Income",
                "Commodities",
                "FX Research",
                "Economic Analysis"
            ],
            "update_frequency": "real-time"
        }
    
    def advisor_assistant(self, query, client_profile):
        """ì¬ë¬´ ìƒë‹´ì‚¬ìš© ì–´ì‹œìŠ¤í„´íŠ¸"""
        # 1. í´ë¼ì´ì–¸íŠ¸ ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ
        client_context = self._get_client_context(client_profile)
        
        # 2. ê´€ë ¨ ì—°êµ¬ ìë£Œ ê²€ìƒ‰
        research_docs = self._search_research(query)
        
        # 3. ì‹œì¥ ë°ì´í„° í†µí•©
        market_data = self._get_market_data()
        
        # 4. GPT-4 ê¸°ë°˜ ë‹µë³€ ìƒì„±
        response = self._generate_response(
            query, client_context, research_docs, market_data
        )
        
        return response
    
    def _get_client_context(self, client_profile):
        """í´ë¼ì´ì–¸íŠ¸ ë§ì¶¤ ì»¨í…ìŠ¤íŠ¸"""
        return {
            "risk_profile": client_profile.get("risk_tolerance"),
            "investment_goals": client_profile.get("goals"),
            "portfolio": client_profile.get("current_holdings"),
            "restrictions": client_profile.get("restrictions", [])
        }
    
    def _search_research(self, query):
        """ì—°êµ¬ ìë£Œ ì‹œë§¨í‹± ê²€ìƒ‰"""
        # ì‹¤ì œë¡œëŠ” ë²¡í„° DB ê²€ìƒ‰
        return [
            "2024 Equity Outlook Report",
            "Tech Sector Analysis Q1 2024",
            "Fed Policy Impact Study"
        ]
    
    def _get_market_data(self):
        """ì‹¤ì‹œê°„ ì‹œì¥ ë°ì´í„°"""
        return {
            "sp500": 4750.23,
            "nasdaq": 14563.89,
            "vix": 13.45,
            "10y_yield": 4.25
        }
    
    def _generate_response(self, query, client_context, research_docs, market_data):
        """í†µí•© ì‘ë‹µ ìƒì„±"""
        prompt = f"""
        As a Morgan Stanley Financial Advisor Assistant:
        
        Client Query: {query}
        Client Risk Profile: {client_context['risk_profile']}
        Investment Goals: {client_context['investment_goals']}
        
        Relevant Research:
        {', '.join(research_docs)}
        
        Current Market:
        S&P 500: {market_data['sp500']}
        VIX: {market_data['vix']}
        
        Provide personalized investment advice considering all factors.
        """
        
        # GPT-4 í˜¸ì¶œ (ì‹¤ì œ êµ¬í˜„ ì‹œ)
        return "Based on our research and your moderate risk profile..."
```

### 4.2 KBêµ­ë¯¼ì€í–‰ AI í¬íŠ¸í´ë¦¬ì˜¤ êµ¬í˜„

```python
class KBBankAIPortfolio:
    """KBêµ­ë¯¼ì€í–‰ AI í¬íŠ¸í´ë¦¬ì˜¤ ì‹œìŠ¤í…œ êµ¬í˜„"""
    
    def __init__(self):
        self.mydata_integration = True
        self.kb_sta_model = self._load_kb_sta()
    
    def _load_kb_sta(self):
        """KB-STA (KB Smart Trading Assistant) ëª¨ë¸"""
        return {
            "model_type": "proprietary",
            "training_data": "10ë…„ê°„ ê¸ˆìœµ ë°ì´í„°",
            "features": [
                "risk_profiling",
                "portfolio_optimization",
                "market_prediction",
                "personalization"
            ]
        }
    
    def generate_portfolio(self, user_id):
        """AI ë§ì¶¤í˜• í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„±"""
        
        # 1. ë§ˆì´ë°ì´í„° ìˆ˜ì§‘
        mydata = self._collect_mydata(user_id)
        
        # 2. ë¦¬ìŠ¤í¬ í”„ë¡œíŒŒì¼ë§
        risk_profile = self._analyze_risk_profile(mydata)
        
        # 3. íˆ¬ì ê°€ëŠ¥ ìì‚° ê³„ì‚°
        investable_assets = self._calculate_investable(mydata)
        
        # 4. AI í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„±
        portfolio = self._optimize_portfolio(
            risk_profile, 
            investable_assets,
            mydata['goals']
        )
        
        # 5. ë¦¬ë°¸ëŸ°ì‹± ì „ëµ
        rebalancing_strategy = self._create_rebalancing_plan(portfolio)
        
        return {
            "portfolio": portfolio,
            "expected_return": self._calculate_expected_return(portfolio),
            "risk_score": risk_profile['score'],
            "rebalancing": rebalancing_strategy
        }
    
    def _collect_mydata(self, user_id):
        """ë§ˆì´ë°ì´í„° í†µí•© ìˆ˜ì§‘"""
        return {
            "bank_accounts": [],
            "investments": [],
            "loans": [],
            "insurance": [],
            "spending_patterns": {},
            "income": 0,
            "goals": []
        }
    
    def _analyze_risk_profile(self, mydata):
        """AI ê¸°ë°˜ ë¦¬ìŠ¤í¬ í”„ë¡œíŒŒì¼ ë¶„ì„"""
        # ì‹¤ì œë¡œëŠ” KB-STA ëª¨ë¸ ì‚¬ìš©
        return {
            "score": 65,  # 0-100
            "category": "ì¤‘ë¦½í˜•",
            "description": "ì•ˆì •ê³¼ ìˆ˜ìµì˜ ê· í˜• ì¶”êµ¬"
        }
    
    def _calculate_investable(self, mydata):
        """íˆ¬ì ê°€ëŠ¥ ìì‚° ê³„ì‚°"""
        # ìˆ˜ì… - ì§€ì¶œ - ë¹„ìƒê¸ˆ = íˆ¬ì ê°€ëŠ¥ì•¡
        monthly_surplus = mydata['income'] - sum(mydata['spending_patterns'].values())
        emergency_fund = mydata['income'] * 3
        
        return max(0, monthly_surplus - emergency_fund / 12)
    
    def _optimize_portfolio(self, risk_profile, assets, goals):
        """í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”"""
        if risk_profile['score'] < 30:
            # ì•ˆì •í˜•
            return {
                "ì±„ê¶Œ": 0.6,
                "ì£¼ì‹": 0.2,
                "ì˜ˆì ê¸ˆ": 0.2
            }
        elif risk_profile['score'] < 70:
            # ì¤‘ë¦½í˜•
            return {
                "ì±„ê¶Œ": 0.3,
                "ì£¼ì‹": 0.5,
                "ëŒ€ì•ˆíˆ¬ì": 0.1,
                "ì˜ˆì ê¸ˆ": 0.1
            }
        else:
            # ê³µê²©í˜•
            return {
                "ì£¼ì‹": 0.7,
                "ëŒ€ì•ˆíˆ¬ì": 0.2,
                "ì±„ê¶Œ": 0.1
            }
    
    def _create_rebalancing_plan(self, portfolio):
        """ë¦¬ë°¸ëŸ°ì‹± ì „ëµ ìˆ˜ë¦½"""
        return {
            "frequency": "quarterly",
            "threshold": 0.05,  # 5% ì´íƒˆ ì‹œ ë¦¬ë°¸ëŸ°ì‹±
            "method": "threshold_based",
            "alerts": True
        }
    
    def _calculate_expected_return(self, portfolio):
        """ê¸°ëŒ€ ìˆ˜ìµë¥  ê³„ì‚°"""
        returns = {
            "ì±„ê¶Œ": 0.04,
            "ì£¼ì‹": 0.08,
            "ëŒ€ì•ˆíˆ¬ì": 0.10,
            "ì˜ˆì ê¸ˆ": 0.03
        }
        
        expected = sum(portfolio.get(asset, 0) * ret 
                      for asset, ret in returns.items())
        
        return f"{expected:.1%}"
```

---

## 5. ì‹¤ìŠµ ê³¼ì œ ë° í‰ê°€

### ê³¼ì œ 1: ChromaDB ë²¡í„° DB êµ¬ì¶•
1. ì œê³µëœ ìƒ˜í”Œ ê±°ë˜ ë°ì´í„°ë¥¼ ChromaDBì— ì €ì¥
2. ë‹¤ì–‘í•œ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
3. ê²€ìƒ‰ ì„±ëŠ¥ ìµœì í™”

### ê³¼ì œ 2: RAG ì±—ë´‡ êµ¬í˜„
1. LangChainì„ ì‚¬ìš©í•œ ê¸ˆìœµ ì±—ë´‡ êµ¬ì¶•
2. ì‚¬ìš©ì ë§ì¶¤í˜• ê¸ˆìœµ ì¡°ì–¸ ìƒì„±
3. ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ êµ¬í˜„

### ê³¼ì œ 3: ì‹¤ì œ ì„œë¹„ìŠ¤ ê¸°íš
1. ìì‹ ë§Œì˜ ê¸ˆìœµ RAG ì„œë¹„ìŠ¤ ê¸°íš
2. í•„ìš”í•œ ë°ì´í„° ì†ŒìŠ¤ ì •ì˜
3. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„

---

## í•µì‹¬ ìš”ì•½

1. **RAG ì‹œìŠ¤í…œ**ì€ ê²€ìƒ‰ê³¼ ìƒì„±ì„ ê²°í•©í•œ ê°•ë ¥í•œ AI ê¸°ìˆ 
2. **ë²¡í„° DB**ëŠ” ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” í•µì‹¬ ì¸í”„ë¼
3. **LangChain**ì„ í†µí•´ ë³µì¡í•œ RAG ì‹œìŠ¤í…œì„ ì‰½ê²Œ êµ¬ì¶• ê°€ëŠ¥
4. **ì‹¤ì œ ê¸ˆìœµê¸°ê´€**ë“¤ì€ ì´ë¯¸ RAGë¥¼ í™œìš©í•œ í˜ì‹ ì  ì„œë¹„ìŠ¤ ì œê³µ ì¤‘

---

## ì°¸ê³  ìë£Œ

- [ChromaDB Documentation](https://docs.trychroma.com/)
- [Pinecone Documentation](https://docs.pinecone.io/)
- [LangChain Documentation](https://python.langchain.com/)
- Morgan Stanley AI Assistant Case Study
- KBêµ­ë¯¼ì€í–‰ AI í¬íŠ¸í´ë¦¬ì˜¤ ì„œë¹„ìŠ¤